{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15704d9",
   "metadata": {},
   "source": [
    "# The Context-Aware MAS Implementation\n",
    "\n",
    "Copyright 2025, Denis Rothman\n",
    "\n",
    "Notebook này triển khai một kiến trúc **Multi-Agent System (MAS)** (Hệ thống đa tác nhân) phục vụ mục đích giáo dục, sử dụng phương pháp **RAG** thông qua **Pinecone** với giao thức **MCP**.\n",
    "\n",
    "Notebook này thực thi lớp xử lý (**execution layer**) của hệ thống **Context-Aware** (nhận biết ngữ cảnh) của chúng ta. Chúng ta sẽ xây dựng một **Multi-Agent System (MAS)** hoàn chỉnh, nơi các **specialized agents** (tác nhân chuyên biệt) phối hợp để hoàn thành một mục tiêu cấp cao, bằng cách khai thác dữ liệu đã được **ingest** vào **Pinecone** trước đó. Kiến trúc cốt lõi được thiết kế để tách biệt rõ ràng giữa **procedural instructions** (hướng dẫn về quy trình - cái \"làm như thế nào\") và **factual data** (dữ liệu thực tế - cái \"gì\"), từ đó cho phép tạo nội dung một cách linh hoạt và có kiểm soát.\n",
    "\n",
    "Dưới đây là chi tiết kế hoạch thực hiện:\n",
    "\n",
    "### 1. Định nghĩa Agent\n",
    "\n",
    "Chúng ta sẽ lập trình ba **specialized agents** đóng vai trò là hạt nhân của hệ thống:\n",
    "\n",
    "* **The Context Librarian:** Thực hiện **procedural RAG** để truy xuất các \"**Semantic Blueprints**\" (bản thiết kế ngữ nghĩa) mang tính phong cách.\n",
    "* **The Researcher:** Sử dụng **factual RAG** để truy vấn và tổng hợp tri thức về một chủ đề nhất định.\n",
    "* **The Writer:** Kết hợp một cách thông minh giữa **blueprint** và kết quả **research** để tạo ra kết quả đầu cuối (**final output**).\n",
    "\n",
    "### 2. The Orchestrator (Điều phối viên)\n",
    "\n",
    "Agent này đóng vai trò quản lý. Nó sử dụng một **LLM** để phân tích mục tiêu của người dùng, chia nhỏ mục tiêu đó thành các truy vấn về **intent** (ý định) và **topic** (chủ đề) riêng biệt cho các agent khác.\n",
    "\n",
    "### 3. Agent Communication (Giao tiếp giữa các Agent)\n",
    "\n",
    "Một **Message Communication Protocol (MCP)** đơn giản được định nghĩa để đảm bảo các agent tương tác với nhau theo cách có cấu trúc và có thể truy vết (**traceable**).\n",
    "\n",
    "### 4. End-to-End Execution (Thực thi đầu cuối)\n",
    "\n",
    "Chúng ta sẽ chạy một vài ví dụ để chứng minh cách hệ thống **MAS** này có thể tạo ra các đầu ra độc nhất cho nhiều chủ đề khác nhau bằng cách truy xuất động các ngữ cảnh (**context**) và tri thức (**knowledge**) chính xác.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0215ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "# Imports and API Key Setup\n",
    "# We will use the OpenAI library to interact with the LLM and Google Colab's\n",
    "# secret manager to securely access your API key.\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# The client will automatically read the OPENAI_API_KEY from your environment.\n",
    "client = OpenAI()\n",
    "print(\"OpenAI client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b429368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "EMBEDDING_DIM = 1536 # Dimension for text-embedding-3-small\n",
    "GENERATION_MODEL = \"gpt-5.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d65fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dino/Documents/learning-2026/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports for this notebook\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "# general imports required in the notebooks of this book\n",
    "import re\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "import copy\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631284f",
   "metadata": {},
   "source": [
    "## 2.Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ffd9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'genai-mas-mcp-ch3' already exists.\n"
     ]
    }
   ],
   "source": [
    "# 2.Initialize Clients\n",
    "# --- Initialize Clients (assuming this is already done) ---\n",
    "\n",
    "# --- Initialize Pinecone Client ---\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# --- Define Index and Namespaces (assuming this is already done) ---\n",
    "INDEX_NAME = 'genai-mas-mcp-ch3'\n",
    "NAMESPACE_KNOWLEDGE = \"KnowledgeStore\"\n",
    "NAMESPACE_CONTEXT = \"ContextLibrary\"\n",
    "spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "\n",
    "# Check if index exists\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"Index '{INDEX_NAME}' not found. Creating new serverless index...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBEDDING_DIM, # Make sure EMBEDDING_DIM is defined\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for index to be ready\n",
    "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "        print(\"Waiting for index to be ready...\")\n",
    "        time.sleep(1)\n",
    "    print(\"Index created successfully. It is new and empty.\")\n",
    "else:\n",
    "    # This block runs ONLY if the index already existed.\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "    # Connect to the index to perform operations\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "\n",
    "# Connect to the index for subsequent operations\n",
    "index = pc.Index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af350c",
   "metadata": {},
   "source": [
    "# 3.Helper Functions (LLM, Embeddings, and MCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea4a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions and MCP structure defined.\n"
     ]
    }
   ],
   "source": [
    "#3.Helper Functions (LLM, Embeddings, and MCP)\n",
    "# -------------------------------------------------------------------------\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def call_llm(system_prompt, user_prompt, temperature=1, json_mode=False):\n",
    "    \"\"\"A centralized function to handle all LLM interactions with retries.\"\"\"\n",
    "    try:\n",
    "        response_format = {\"type\": \"json_object\"} if json_mode else {\"type\": \"text\"}\n",
    "        response = client.chat.completions.create(\n",
    "            model=GENERATION_MODEL,\n",
    "            response_format=response_format,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM: {e}\")\n",
    "        return f\"LLM Error: {e}\"\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generates embeddings for a single text query with retries.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=EMBEDDING_MODEL)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def create_mcp_message(sender, content, metadata=None):\n",
    "    \"\"\"Creates a standardized MCP message (Educational Version).\"\"\"\n",
    "    return {\n",
    "        \"protocol_version\": \"1.1 (RAG-Enhanced)\",\n",
    "        \"sender\": sender,\n",
    "        \"content\": content,\n",
    "        \"metadata\": metadata or {}\n",
    "    }\n",
    "\n",
    "def display_mcp(message, title=\"MCP Message\"):\n",
    "    \"\"\"Helper function to display MCP messages clearly during the trace.\"\"\"\n",
    "    print(f\"\\n--- {title} (Sender: {message['sender']}) ---\")\n",
    "    # Display content snippet or keys if content is complex\n",
    "    if isinstance(message['content'], dict):\n",
    "         print(f\"Content Keys: {list(message['content'].keys())}\")\n",
    "    else:\n",
    "        print(f\"Content: {textwrap.shorten(str(message['content']), width=100)}\")\n",
    "    # Display metadata keys\n",
    "    print(f\"Metadata Keys: {list(message['metadata'].keys())}\")\n",
    "    print(\"-\" * (len(title) + 25))\n",
    "\n",
    "def query_pinecone(query_text, namespace, top_k=1):\n",
    "    \"\"\"Embeds the query text and searches the specified Pinecone namespace.\"\"\"\n",
    "    try:\n",
    "        query_embedding = get_embedding(query_text)\n",
    "        response = index.query(\n",
    "            vector=query_embedding,\n",
    "            namespace=namespace,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        return response['matches']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Pinecone (Namespace: {namespace}): {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"Helper functions and MCP structure defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5bc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.Agent Definitions\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# === 4.1. Context Librarian Agent (Procedural RAG) ===\n",
    "def agent_context_librarian(mcp_message):\n",
    "    \"\"\"\n",
    "    Retrieves the appropriate Semantic Blueprint from the Context Library.\n",
    "    \"\"\"\n",
    "    print(\"\\n[Librarian] Activated. Analyzing intent...\")\n",
    "    requested_intent = mcp_message['content']['intent_query']\n",
    "\n",
    "    # Query Pinecone Context Namespace\n",
    "    results = query_pinecone(requested_intent, NAMESPACE_CONTEXT, top_k=1)\n",
    "\n",
    "    if results:\n",
    "        match = results[0]\n",
    "        print(f\"[Librarian] Found blueprint '{match['id']}' (Score: {match['score']:.2f})\")\n",
    "        # Retrieve the blueprint JSON string stored in metadata\n",
    "        blueprint_json = match['metadata']['blueprint_json']\n",
    "        content = {\"blueprint\": blueprint_json}\n",
    "    else:\n",
    "        print(\"[Librarian] No specific blueprint found. Returning default.\")\n",
    "        # Fallback default\n",
    "        content = {\"blueprint\": json.dumps({\"instruction\": \"Generate the content neutrally.\"})}\n",
    "\n",
    "    return create_mcp_message(\"Librarian\", content)\n",
    "\n",
    "# === 4.2. Researcher Agent (Factual RAG) ===\n",
    "def agent_researcher(mcp_message):\n",
    "    \"\"\"\n",
    "    Retrieves and synthesizes factual information from the Knowledge Base.\n",
    "    \"\"\"\n",
    "    print(\"\\n[Researcher] Activated. Investigating topic...\")\n",
    "    topic = mcp_message['content']['topic_query']\n",
    "\n",
    "    # Query Pinecone Knowledge Namespace\n",
    "    results = query_pinecone(topic, NAMESPACE_KNOWLEDGE, top_k=3)\n",
    "\n",
    "    if not results:\n",
    "        print(\"[Researcher] No relevant information found.\")\n",
    "        return create_mcp_message(\"Researcher\", {\"facts\": \"No data found.\"})\n",
    "\n",
    "    # Synthesize the findings (Retrieve-and-Synthesize)\n",
    "    print(f\"[Researcher] Found {len(results)} relevant chunks. Synthesizing...\")\n",
    "    source_texts = [match['metadata']['text'] for match in results]\n",
    "\n",
    "    system_prompt = \"\"\"Bạn là một chuyên gia AI về tổng hợp nghiên cứu (research synthesis). \n",
    "Hãy tổng hợp các văn bản nguồn (source texts) đã cung cấp thành một bản tóm tắt ngắn gọn, trình bày dưới dạng danh sách (bullet-pointed summary) và bám sát chủ đề của người dùng. \n",
    "Yêu cầu:\n",
    "1. Tập trung nghiêm ngặt vào các sự kiện thực tế (facts) có trong nguồn tài liệu. \n",
    "2. Tuyệt đối không thêm thông tin bên ngoài (outside information).\"\"\"\n",
    "\n",
    "    user_prompt = f\"Topic: {topic}\\n\\nSources:\\n\" + \"\\n\\n---\\n\\n\".join(source_texts)\n",
    "\n",
    "    findings = call_llm(system_prompt, user_prompt)\n",
    "\n",
    "    return create_mcp_message(\"Researcher\", {\"facts\": findings})\n",
    "\n",
    "# === 4.3. Writer Agent (Generation) ===\n",
    "def agent_writer(mcp_message):\n",
    "    \"\"\"\n",
    "    Combines the factual research with the semantic blueprint to generate the final output.\n",
    "    \"\"\"\n",
    "    print(\"\\n[Writer] Activated. Applying blueprint to facts...\")\n",
    "\n",
    "    facts = mcp_message['content']['facts']\n",
    "    # The blueprint is passed as a JSON string\n",
    "    blueprint_json_string = mcp_message['content']['blueprint']\n",
    "\n",
    "    # The Writer's System Prompt incorporates the dynamically retrieved blueprint\n",
    "    system_prompt = f\"\"\"Bạn là một chuyên gia AI về tạo nội dung (content generation).\n",
    "    Nhiệm vụ của bạn là tạo nội dung dựa trên các KẾT QUẢ NGHIÊN CỨU (RESEARCH FINDINGS) được cung cấp.\n",
    "    Quan trọng nhất, bạn PHẢI cấu trúc, định hình phong cách và thiết lập các giới hạn cho kết quả đầu ra dựa trên các quy tắc được định nghĩa trong BẢN THIẾT KẾ NGỮ NGHĨA (SEMANTIC BLUEPRINT) dưới đây.\n",
    "\n",
    "    --- SEMANTIC BLUEPRINT (JSON) ---\n",
    "    {blueprint_json_string}\n",
    "    --- END SEMANTIC BLUEPRINT ---\n",
    "\n",
    "    Hãy tuân thủ nghiêm ngặt các hướng dẫn, chỉ dẫn phong cách (style guides) và mục tiêu trong blueprint. \n",
    "    Blueprint xác định CÁCH bạn viết (HOW); nghiên cứu xác định nội dung bạn viết về CÁI GÌ (WHAT).\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    --- RESEARCH FINDINGS ---\n",
    "    {facts}\n",
    "    --- END RESEARCH FINDINGS ---\n",
    "\n",
    "    Generate the content now.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the final content (slightly higher temperature for potential creativity)\n",
    "    final_output = call_llm(system_prompt, user_prompt)\n",
    "\n",
    "    return create_mcp_message(\"Writer\", {\"output\": final_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3b2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5.The Orchestrator\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def orchestrator(high_level_goal):\n",
    "    \"\"\"\n",
    "    Manages the workflow of the Context-Aware MAS.\n",
    "    Analyzes the goal, retrieves context and facts, and coordinates generation.\n",
    "    \"\"\"\n",
    "    print(f\"=== [Orchestrator] Starting New Task ===\")\n",
    "    print(f\"Goal: {high_level_goal}\")\n",
    "\n",
    "    # Step 0: Analyze Goal (Determine Intent and Topic)\n",
    "    # We use the LLM to separate the desired style (intent) from the subject matter (topic).\n",
    "    print(\"\\n[Orchestrator] Analyzing Goal...\")\n",
    "    analysis_system_prompt = \"\"\"Bạn là một chuyên gia phân tích mục tiêu (goal analyst). \n",
    "Hãy phân tích mục tiêu cấp cao (high-level goal) của người dùng và trích xuất hai thành phần sau:\n",
    "\n",
    "1. 'intent_query': Một cụm từ mô tả tóm tắt phong cách, giọng văn, hoặc định dạng mong muốn, được tối ưu hóa để tìm kiếm trong thư viện ngữ cảnh (context library). \n",
    "   (Ví dụ: \"suspenseful narrative blueprint\", \"objective technical explanation structure\").\n",
    "\n",
    "2. 'topic_query': Một cụm từ súc tích tóm tắt chủ đề thực tế hoặc nội dung chuyên môn cần thiết. \n",
    "   (Ví dụ: \"Juno mission objectives and power\", \"Apollo 11 landing details\").\n",
    "\n",
    "Yêu cầu: CHỈ phản hồi bằng một đối tượng JSON chứa hai khóa (keys) này.\"\"\"\n",
    "\n",
    "    # We request JSON mode for reliable parsing\n",
    "    analysis_result = call_llm(analysis_system_prompt, high_level_goal, json_mode=True)\n",
    "\n",
    "    try:\n",
    "        analysis = json.loads(analysis_result)\n",
    "        intent_query = analysis['intent_query']\n",
    "        topic_query = analysis['topic_query']\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        print(f\"[Orchestrator] Error: Could not parse analysis JSON. Raw Analysis: {analysis_result}. Aborting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Orchestrator: Intent Query: '{intent_query}'\")\n",
    "    print(f\"Orchestrator: Topic Query: '{topic_query}'\")\n",
    "\n",
    "\n",
    "    # Step 1: Get the Context Blueprint (Procedural RAG)\n",
    "    mcp_to_librarian = create_mcp_message(\n",
    "        sender=\"Orchestrator\",\n",
    "        content={\"intent_query\": intent_query}\n",
    "    )\n",
    "    # display_mcp(mcp_to_librarian, \"Orchestrator -> Librarian\")\n",
    "    mcp_from_librarian = agent_context_librarian(mcp_to_librarian)\n",
    "    display_mcp(mcp_from_librarian, \"Librarian -> Orchestrator\")\n",
    "\n",
    "    context_blueprint = mcp_from_librarian['content'].get('blueprint')\n",
    "    if not context_blueprint: return\n",
    "\n",
    "    # Step 2: Get the Factual Knowledge (Factual RAG)\n",
    "    mcp_to_researcher = create_mcp_message(\n",
    "        sender=\"Orchestrator\",\n",
    "        content={\"topic_query\": topic_query}\n",
    "    )\n",
    "    # display_mcp(mcp_to_researcher, \"Orchestrator -> Researcher\")\n",
    "    mcp_from_researcher = agent_researcher(mcp_to_researcher)\n",
    "    display_mcp(mcp_from_researcher, \"Researcher -> Orchestrator\")\n",
    "\n",
    "    research_findings = mcp_from_researcher['content'].get('facts')\n",
    "    if not research_findings: return\n",
    "\n",
    "    # Step 3: Generate the Final Output\n",
    "    # Combine the outputs for the Writer Agent\n",
    "    writer_task = {\n",
    "        \"blueprint\": context_blueprint,\n",
    "        \"facts\": research_findings\n",
    "    }\n",
    "\n",
    "    mcp_to_writer = create_mcp_message(\n",
    "        sender=\"Orchestrator\",\n",
    "        content=writer_task\n",
    "    )\n",
    "    # display_mcp(mcp_to_writer, \"Orchestrator -> Writer\")\n",
    "    mcp_from_writer = agent_writer(mcp_to_writer)\n",
    "    display_mcp(mcp_from_writer, \"Writer -> Orchestrator\")\n",
    "\n",
    "    final_result = mcp_from_writer['content'].get('output')\n",
    "\n",
    "    print(\"\\n=== [Orchestrator] Task Complete ===\")\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c276e6",
   "metadata": {},
   "source": [
    "#  6.Running examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4ef78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********  1: SUSPENSEFUL NARRATIVE **********\n",
      "=== [Orchestrator] Starting New Task ===\n",
      "Goal: Viết một phân cảnh ngắn, đầy kịch tính cho một câu chuyện thiếu nhi về sự kiện tàu Apollo 11 đổ bộ lên Mặt Trăng, trong đó làm nổi bật những mối nguy hiểm.\n",
      "\n",
      "[Orchestrator] Analyzing Goal...\n",
      "Orchestrator: Intent Query: 'dramatic childrens story scene structure'\n",
      "Orchestrator: Topic Query: 'Apollo 11 moon landing dangers for kids'\n",
      "\n",
      "[Librarian] Activated. Analyzing intent...\n",
      "[Librarian] Found blueprint 'blueprint_suspense_narrative' (Score: 0.27)\n",
      "\n",
      "--- Librarian -> Orchestrator (Sender: Librarian) ---\n",
      "Content Keys: ['blueprint']\n",
      "Metadata Keys: []\n",
      "--------------------------------------------------\n",
      "\n",
      "[Researcher] Activated. Investigating topic...\n",
      "[Researcher] Found 3 relevant chunks. Synthesizing...\n",
      "\n",
      "--- Researcher -> Orchestrator (Sender: Researcher) ---\n",
      "Content Keys: ['facts']\n",
      "Metadata Keys: []\n",
      "---------------------------------------------------\n",
      "\n",
      "[Writer] Activated. Applying blueprint to facts...\n",
      "\n",
      "--- Writer -> Orchestrator (Sender: Writer) ---\n",
      "Content Keys: ['output']\n",
      "Metadata Keys: []\n",
      "-----------------------------------------------\n",
      "\n",
      "=== [Orchestrator] Task Complete ===\n",
      "\n",
      "******** FINAL OUTPUT 1 **********\n",
      "\n",
      "Tiếng ù nền từ hệ thống liên lạc vang trong tai.  \n",
      "Mờ xa bên dưới, Mặt Trăng trôi qua như một khối đá xám chết lặng.\n",
      "\n",
      "Neil siết tay lên cần điều khiển.  \n",
      "Eagle đang trôi thấp dần.  \n",
      "Quá thấp.  \n",
      "Quá nhanh.\n",
      "\n",
      "“Computer program alarm…” Giọng báo cáo khô khốc, lập lại, cắt vào không gian chật hẹp.  \n",
      "Những con số trên bảng điều khiển nhảy loạn.  \n",
      "Không gian trước mặt anh chỉ là một biển bụi xám, lỗ chỗ hố va chạm, bóng đổ sâu như miệng vực.\n",
      "\n",
      "“Houston, đây là Eagle…”  \n",
      "Anh cố giữ giọng phẳng. Tim lại không phẳng chút nào.\n",
      "\n",
      "Bên ngoài cửa sổ, bề mặt Mặt Trăng lướt qua, mỗi giây một gần hơn.  \n",
      "Những hố tròn đen ngòm.  \n",
      "Những tảng đá lớn ném bóng nhọn hoắt trên nền sáng lạnh.  \n",
      "Không có màu sắc.  \n",
      "Chỉ xám.  \n",
      "Và đen.\n",
      "\n",
      "Máy tính muốn đưa họ xuống một vùng đầy đá.  \n",
      "Nếu cứ để tự động, họ có thể hạ ngay lên một khối đá khổng lồ.  \n",
      "Hoặc đổ nhào, vỡ nát.  \n",
      "Trong im lặng tuyệt đối không có không khí để truyền âm thanh.\n",
      "\n",
      "Anh ngước nhanh qua trái, nhìn Buzz.  \n",
      "Mắt Buzz dán vào các đồng hồ, tay lật sổ, đọc to:  \n",
      "“Altitude… velocity… 60 seconds fuel remaining.”\n",
      "\n",
      "Sáu mươi giây.  \n",
      "Một phút.  \n",
      "Một phút để chọn giữa bề mặt an toàn và hố sâu.  \n",
      "Giữa đáp xuống hay trở thành một tia sáng lặng câm trên nền bụi.\n",
      "\n",
      "Neil tắt sự can thiệp của máy tính.  \n",
      "Eagle bỗng như trượt tự do trong lòng bàn tay anh.  \n",
      "Anh cảm nhận lực nhẹ thay đổi, tiếng rung của động cơ điều hướng nhỏ phía dưới thân tàu.  \n",
      "Bên ngoài, ánh Mặt Trời trườn qua mép cửa sổ, kéo theo những vệt bóng sắc, cứa vào các công tắc và nút bấm.\n",
      "\n",
      "“Manual control.”  \n",
      "Anh nói, nhưng câu đó cũng như để trấn an chính mình.\n",
      "\n",
      "Dưới kia, một bề mặt bằng phẳng hơn hiện ra.  \n",
      "Ít hố hơn.  \n",
      "Ít đá lớn hơn.  \n",
      "Nhưng khoảng cách đang thu hẹp rất nhanh.\n",
      "\n",
      "“Altitude?”  \n",
      "“Thirty… twenty-five…” Buzz đáp, giọng gấp gáp nhưng vẫn giữ được nhịp.  \n",
      "“Fuel: 30 seconds.”\n",
      "\n",
      "Khoang tàu càng lúc càng nóng.  \n",
      "Không phải vì nhiệt, mà vì mồ hôi.  \n",
      "Mồ hôi bám vào lưng, trán, dính chặt dưới mũ bay.  \n",
      "Tiếng tim mình, Neil chỉ nghe qua cảm giác nhịp đập nơi cổ, nơi tay.  \n",
      "Tất cả bị bọc kín trong lớp vỏ kim loại mỏng manh, trôi giữa không gian đen đặc.\n",
      "\n",
      "Qua kênh liên lạc, giọng của Houston vang lên, nhỏ và xa như từ đáy giếng:  \n",
      "“Eagle, chúng tôi theo sát… Fuel reading?”\n",
      "\n",
      "Buzz nuốt nước bọt:  \n",
      "“Less than 30 seconds. Neil…”\n",
      "\n",
      "Eagle tiếp tục trôi ngang trên mặt trăng như một chiếc thuyền bay sát mặt biển đá.  \n",
      "Bên dưới, đám bụi vẫn yên, im lìm chờ cú chạm.  \n",
      "Neil kéo nhẹ cần.  \n",
      "Động cơ gầm lên, những tia khí vô hình phả xuống.  \n",
      "Bóng của Eagle hiện mờ trên mặt trăng, đậm dần, dài ra, méo mó, như một chiếc bóng đen đang trèo ngược lên họ.\n",
      "\n",
      "“Twenty seconds fuel.”  \n",
      "Bàn tay anh nắm chặt hơn.  \n",
      "Mọi thứ thu hẹp lại: khung cửa sổ, một dải đất phẳng phía trước, vài con số chớp nháy trên bảng điều khiển.  \n",
      "Phần còn lại của vũ trụ biến mất.\n",
      "\n",
      "Mặt trăng phóng to từng centimét.  \n",
      "Bụi bắt đầu tung lên thành những lọn mịn như khói, chuyển động chậm chạp trong trọng lực yếu.  \n",
      "Chúng lượn quanh, che mờ tầm nhìn.  \n",
      "Một màn sương xám, không khí thì không có, nhưng bụi thì có.\n",
      "\n",
      "“Fifteen seconds.”  \n",
      "Giọng Buzz nay đã khàn.  \n",
      "Anh cũng biết rõ như Neil: hết nhiên liệu, họ sẽ chỉ còn là một khối kim loại rơi tự do.  \n",
      "Không có lần thứ hai.\n",
      "\n",
      "Neil hạ mũi tàu.  \n",
      "Anh chọn điểm đáp giữa hai hố nhỏ, tránh một tảng đá đen như cái móng tay khổng lồ, nhô lên như cạm bẫy.  \n",
      "\n",
      "Bụi dày thêm.  \n",
      "Cửa sổ chỉ còn một màn xám quay cuồng.  \n",
      "Bên dưới đó, là đá.  \n",
      "Nếu tính sai…  \n",
      "\n",
      "Neil giữ lực đẩy vừa đủ, mắt đảo giữa độ cao, tốc độ, cảm giác rung.  \n",
      "Anh phải “cảm” được mặt trăng mà không được chạm.  \n",
      "Vẫn còn cao.  \n",
      "Vẫn còn nhanh.\n",
      "\n",
      "“Five… four…”  \n",
      "Không ai nói nữa.  \n",
      "Không cần.  \n",
      "Không kịp.\n",
      "\n",
      "Rồi…  \n",
      "Một cú chạm.  \n",
      "Rất nhẹ.  \n",
      "Một sự ngắt quãng trong rung động của kim loại.\n",
      "\n",
      "Eagle khựng lại.  \n",
      "Rung.  \n",
      "Rồi đứng yên.\n",
      "\n",
      "Bụi xám tiếp tục bay quanh, chậm dần, rơi trở lại mặt trăng trong im lặng hoàn toàn.  \n",
      "Không có tiếng va đập ầm ầm.  \n",
      "Không có tiếng bánh đáp rít trên đá.  \n",
      "Chỉ có sự lắng xuống của mọi dao động, như thể cả thân tàu đang thở ra lần đầu sau một cú nín thở dài.\n",
      "\n",
      "Neil nhìn bảng điều khiển.  \n",
      "Các chỉ số ổn định.  \n",
      "Nhiên liệu… còn lại ít đến mức anh không muốn nghĩ tiếp.\n",
      "\n",
      "Giọng Houston vỡ ra trong tai nghe, căng đến nỗi như đứt dây:  \n",
      "“Trạm đây Houston… chúng tôi đang nghe.”\n",
      "\n",
      "Buzz nhìn Neil.  \n",
      "Khoảnh khắc ngắn ngủi, hai người im lặng.  \n",
      "Lạnh.  \n",
      "Tĩnh.  \n",
      "Phía ngoài kia là một thế giới không có gió, không có tiếng động, chỉ có bóng của Eagle đổ dài trên một bề mặt chưa từng in dấu chân người.\n",
      "\n",
      "Neil ấn nút, báo hiệu:  \n",
      "“Houston, đây là Trạm Căn cứ Tĩnh Lặng.”  \n",
      "Một nhịp thở.  \n",
      "“Eagle đã hạ cánh.”\n",
      "\n",
      "Trong khoảnh khắc ấy, bên ngoài thành tàu mỏng, Mặt Trăng chờ đợi.  \n",
      "Một khối cầu xám bạc, lạnh giá, im lặng.  \n",
      "Nhưng từ giờ, nó không còn hoàn toàn xa lạ nữa.  \n",
      "Bởi chỉ cách vài cm kim loại, có một con người đang ngồi đó, tim vẫn đập nhanh, tay còn vết run mờ, chuẩn bị mở cửa…  \n",
      "Và đặt bước chân đầu tiên lên nơi mà chỉ vài chục giây trước, suýt nữa đã trở thành mộ đá của chính mình.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Example 1: Requesting a specific style (Suspense) for a topic (Apollo 11)\n",
    "print(\"********  1: SUSPENSEFUL NARRATIVE **********\")\n",
    "goal_1 = \"Viết một phân cảnh ngắn, đầy kịch tính cho một câu chuyện thiếu nhi về sự kiện tàu Apollo 11 đổ bộ lên Mặt Trăng, trong đó làm nổi bật những mối nguy hiểm.\"\n",
    "result_1 = orchestrator(goal_1)\n",
    "\n",
    "print(\"\\n******** FINAL OUTPUT 1 **********\\n\")\n",
    "print(result_1)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81759672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

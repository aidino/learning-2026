{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad9bb97",
   "metadata": {},
   "source": [
    "# RAG Pipeline - Data Ingestion (Context and Knowledge)\n",
    "\n",
    "Copyright 2025-2026, Denis Rothman\n",
    "\n",
    "\n",
    "Notebook này giải quyết bước đầu tiên cực kỳ quan trọng trong việc xây dựng một **RAG pipeline** phức tạp: **data ingestion** (nạp dữ liệu). Về cơ bản, chúng ta đang thiết lập \"bộ não\" cho **agent** bằng cách cung cấp cho nó hai loại thông tin riêng biệt—ngữ cảnh về quy trình (**procedural \"how-to\" context**) và kiến thức thực tế (**factual \"what-is\" knowledge**). Khi kết thúc, bạn sẽ có một **Pinecone vector database** đã được chuẩn bị đầy đủ, sẵn sàng vận hành một AI thông minh hơn và có khả năng nhận biết ngữ cảnh (**context-aware**).\n",
    "\n",
    "Dưới đây là tóm tắt các nội dung mà notebook này thực hiện:\n",
    "\n",
    "* **Environment Setup (Thiết lập môi trường):** Cài đặt tất cả các thư viện Python cần thiết (`openai`, `pinecone`, `tiktoken`, v.v.) và cấu hình bảo mật cho các **API keys**.\n",
    "* **Vector Database Prep (Chuẩn bị cơ sở dữ liệu vector):** Kết nối với **Pinecone index**, tạo mới nếu chưa tồn tại và xóa dữ liệu cũ để đảm bảo một hệ thống sạch (**clean slate**).\n",
    "* **Procedural Context (Ngữ cảnh quy trình):** Định nghĩa và tạo **embeddings** cho các \"Semantic Blueprints\" — các hướng dẫn về phong cách và cấu trúc của chúng ta — sau đó tải chúng lên một **namespace** chuyên dụng có tên là `ContextLibrary`.\n",
    "* **Factual Knowledge (Kiến thức thực tế):** Thực hiện **chunking** (chia nhỏ) văn bản thô thành các đoạn tối ưu bằng cách sử dụng một **tokenizer**, tạo **embeddings** cho chúng và tải toàn bộ lên một **namespace** riêng biệt gọi là `KnowledgeStore` để phục vụ việc truy xuất dữ liệu thực tế (**factual recall**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833019e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dino/Documents/learning-2026/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports for this notebook\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "# general imports required in the notebooks of this book\n",
    "import re\n",
    "import textwrap\n",
    "from IPython.display import display, Markdown\n",
    "import copy\n",
    "\n",
    "# ServerlessSpec: dùng để tạo index vector\n",
    "# retry: dùng để retry khi có lỗi\n",
    "# stop_after_attempt: dùng để stop khi retry quá lần\n",
    "# wait_random_exponential: dùng để wait random exponential, nghĩa là đợi ngẫu nhiên\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e1838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# The client will automatically read the OPENAI_API_KEY from your environment.\n",
    "client = OpenAI()\n",
    "print(\"OpenAI client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea871a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "EMBEDDING_DIM = 1536 # Dimension for text-embedding-3-small\n",
    "GENERATION_MODEL = \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9adeda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5977d",
   "metadata": {},
   "source": [
    "## 2.Initialize Clients\n",
    "\n",
    "\n",
    "### 1. Các khái niệm cơ bản và cách tổ chức dữ liệu trong Pinecone\n",
    "Pinecone là một **cơ sở dữ liệu vector (vector database)** được sử dụng để lưu trữ và truy xuất các bản biểu diễn số học (embeddings) của dữ liệu. Trong hệ thống này, dữ liệu được tổ chức theo cấu trúc phân cấp:\n",
    "\n",
    "*   **Index (Chỉ mục):** Đây là đơn vị lưu trữ cao nhất trong Pinecone, giống như một cơ sở dữ liệu riêng biệt. Một chỉ mục sẽ giữ toàn bộ các vector cần thiết cho dự án.\n",
    "*   **Namespace (Không gian tên):** Đây là một tính năng cho phép **chia một chỉ mục duy nhất thành các phần tách biệt nghiêm ngặt**,. Điều này cực kỳ quan trọng trong kiến trúc **RAG kép (dual RAG)** để quản lý các loại dữ liệu khác nhau mà không bị lẫn lộn.\n",
    "\n",
    "### 2. Vai trò của Index Name và Namespace Name\n",
    "Trong bối cảnh của tài liệu, việc phân chia này phục vụ một mục đích chiến lược:\n",
    "\n",
    "*   **Index Name (Tên chỉ mục):** Định danh duy nhất cho kho lưu trữ vector của dự án (ví dụ: `genai-mas-mcp-ch3`). Nó xác định phạm vi tài nguyên mà hệ thống sẽ truy cập.\n",
    "*   **Namespace Name (Tên không gian tên):**\n",
    "    *   **KnowledgeStore:** Dùng để lưu trữ các vector từ **dữ liệu thực tế (factual data)**,. Đây là nơi tác nhân Nhà nghiên cứu (Researcher agent) tìm kiếm thông tin để trả lời câu hỏi \"cái gì\".\n",
    "    *   **ContextLibrary:** Dùng để lưu trữ các vector từ **bản thiết kế ngữ nghĩa (semantic blueprints)** hoặc các hướng dẫn quy trình,. Đây là nơi tác nhân Thủ thư (Librarian agent) truy tìm \"cách thức\" để cấu trúc phản hồi.\n",
    "\n",
    "### 3. Giải thích chi tiết đoạn code khởi tạo\n",
    "\n",
    "Đoạn code của bạn thực hiện các bước thiết lập nền tảng sau:\n",
    "\n",
    "*   **`pc = Pinecone(api_key=PINECONE_API_KEY)`:** Dòng này khởi tạo kết nối với dịch vụ Pinecone bằng khóa API bảo mật. Khóa này thường được lấy từ trình quản lý bí mật (như Google Colab Secrets) để đảm bảo an toàn,.\n",
    "*   **`INDEX_NAME = 'genai-mas-mcp-ch3'`:** Thiết lập tên cho chỉ mục sẽ được sử dụng xuyên suốt chương.\n",
    "*   **`NAMESPACE_KNOWLEDGE` và `NAMESPACE_CONTEXT`:** Định nghĩa tên cho hai không gian tên riêng biệt để thực hiện chiến lược RAG kép, cho phép tách biệt tri thức thực tế và hướng dẫn phong cách,.\n",
    "*   **`spec = ServerlessSpec(cloud='aws', region='us-east-1')`:** Xác định cấu hình hạ tầng **serverless (không máy chủ)** của Pinecone. Đây là kiến trúc được khuyến khích cho các gói miễn phí, chỉ định việc chạy trên dịch vụ đám mây AWS tại khu vực `us-east-1`.\n",
    "\n",
    "---\n",
    "\n",
    "**Ví dụ ẩn dụ:**\n",
    "Hãy tưởng tượng Pinecone là một **thư viện lớn (Index)**. Trong thư viện này, bạn chia làm hai khu vực riêng biệt (**Namespace**): một khu vực chứa **sách bách khoa toàn thư** (KnowledgeStore - nơi chứa sự thật) và một khu vực chứa **sách hướng dẫn kỹ năng viết** (ContextLibrary - nơi chứa cách trình bày). Việc khởi tạo client giống như việc bạn **đăng ký thẻ quản lý thư viện** để có quyền truy cập và sắp xếp các kệ sách này theo đúng vị trí của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0daac302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'genai-mas-mcp-ch3' not found. Creating new serverless index...\n",
      "Index created successfully. It is new and empty.\n"
     ]
    }
   ],
   "source": [
    "# 2.Initialize Clients\n",
    "# --- Initialize Clients (assuming this is already done) ---\n",
    "\n",
    "# --- Initialize Pinecone Client ---\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# --- Define Index and Namespaces (assuming this is already done) ---\n",
    "INDEX_NAME = 'genai-mas-mcp-ch3'\n",
    "NAMESPACE_KNOWLEDGE = \"KnowledgeStore\"\n",
    "NAMESPACE_CONTEXT = \"ContextLibrary\"\n",
    "spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "\n",
    "# Check if index exists\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"Index '{INDEX_NAME}' not found. Creating new serverless index...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBEDDING_DIM,\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for index to be ready\n",
    "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "        print(\"Waiting for index to be ready...\")\n",
    "        time.sleep(1)\n",
    "    print(\"Index created successfully. It is new and empty.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists. Clearing namespaces for a fresh start...\")\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    namespaces_to_clear = [NAMESPACE_KNOWLEDGE, NAMESPACE_CONTEXT]\n",
    "\n",
    "    for namespace in namespaces_to_clear:\n",
    "        # Check if namespace exists and has vectors before deleting\n",
    "        stats = index.describe_index_stats()\n",
    "        if namespace in stats.namespaces and stats.namespaces[namespace].vector_count > 0:\n",
    "            print(f\"Clearing namespace '{namespace}'...\")\n",
    "            index.delete(delete_all=True, namespace=namespace)\n",
    "\n",
    "            # **CRITICAL FUNCTTION: Wait for deletion to complete**\n",
    "            while True:\n",
    "                stats = index.describe_index_stats()\n",
    "                if namespace not in stats.namespaces or stats.namespaces[namespace].vector_count == 0:\n",
    "                    print(f\"Namespace '{namespace}' cleared successfully.\")\n",
    "                    break\n",
    "                print(f\"Waiting for namespace '{namespace}' to clear...\")\n",
    "                time.sleep(5) # Poll every 5 seconds\n",
    "        else:\n",
    "            print(f\"Namespace '{namespace}' is already empty or does not exist. Skipping.\")\n",
    "\n",
    "# Connect to the index for subsequent operations\n",
    "index = pc.Index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc28321",
   "metadata": {},
   "source": [
    "# 3.Data Preparation: The Context Library (Procedural RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e60f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared 3 context blueprints.\n"
     ]
    }
   ],
   "source": [
    "context_blueprints = [\n",
    "    {\n",
    "        \"id\": \"blueprint_suspense_narrative\",\n",
    "        \"description\": \"Một Bản thiết kế Ngữ nghĩa (Semantic Blueprint) chính xác được thiết kế để tạo ra các câu chuyện kịch tính và căng thẳng, phù hợp với truyện thiếu nhi. Tập trung vào bầu không khí, các mối đe dọa tiềm tàng và tác động cảm xúc. Lý tưởng cho viết lách sáng tạo.\",\n",
    "        \"blueprint\": json.dumps({\n",
    "              \"scene_goal\": \"Tăng cường sự căng thẳng và tạo ra sự hồi hộp.\",\n",
    "              \"style_guide\": \"Sử dụng các câu ngắn, sắc bén. Tập trung vào các chi tiết cảm giác (âm thanh, bóng đổ). Duy trì tông giọng hơi kỳ bí nhưng phù hợp với lứa tuổi.\",\n",
    "              \"participants\": [\n",
    "                { \"role\": \"Agent\", \"description\": \"Nhân vật chính đang trải qua các sự kiện.\" },\n",
    "                { \"role\": \"Source_of_Threat\", \"description\": \"Mối nguy hiểm hoặc bí ẩn tiềm ẩn.\" }\n",
    "              ],\n",
    "            \"instruction\": \"Viết lại các dữ kiện đã cung cấp thành một câu chuyện, tuân thủ nghiêm ngặt scene_goal và style_guide.\"\n",
    "            })\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"blueprint_technical_explanation\",\n",
    "        \"description\": \"Một Bản thiết kế Ngữ nghĩa được thiết kế để giải thích hoặc phân tích kỹ thuật. Bản thiết kế này tập trung vào sự rõ ràng, tính khách quan và cấu trúc. Lý tưởng để phân tích các quy trình phức tạp, giải thích cơ chế hoặc tóm tắt các phát hiện khoa học.\",\n",
    "        \"blueprint\": json.dumps({\n",
    "              \"scene_goal\": \"Giải thích cơ chế hoặc các phát hiện một cách rõ ràng và súc tích.\",\n",
    "              \"style_guide\": \"Duy trì tông giọng khách quan và trang trọng. Sử dụng thuật ngữ chính xác. Ưu tiên độ chính xác thực tế và sự rõ ràng hơn là lối viết kể chuyện hoa mỹ.\",\n",
    "              \"structure\": [\"Định nghĩa\", \"Chức năng/Vận hành\", \"Các phát hiện chính/Tác động\"],\n",
    "              \"instruction\": \"Tổ chức các dữ kiện đã cung cấp vào cấu trúc đã định nghĩa, tuân thủ style_guide.\"\n",
    "            })\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"blueprint_casual_summary\",\n",
    "        \"description\": \"Một bối cảnh hướng mục tiêu để tạo ra bản tóm tắt thân mật, dễ đọc. Tập trung vào sự ngắn gọn và dễ tiếp cận, giải thích các khái niệm một cách đơn giản.\",\n",
    "        \"blueprint\": json.dumps({\n",
    "              \"scene_goal\": \"Tóm tắt thông tin một cách nhanh chóng và thân mật.\",\n",
    "              \"style_guide\": \"Sử dụng ngôn ngữ không trang trọng. Giữ nội dung ngắn gọn và lôi cuốn. Hãy tưởng tượng như đang giải thích cho một người bạn.\",\n",
    "              \"instruction\": \"Tóm tắt các dữ kiện đã cung cấp bằng cách sử dụng hướng dẫn phong cách thân mật (casual style guide).\"\n",
    "            })\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\nPrepared {len(context_blueprints)} context blueprints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11472b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_data_raw = \"\"\"\n",
    "Khám phá không gian là việc sử dụng thiên văn học và công nghệ vũ trụ để thám hiểm không gian bên ngoài. Giai đoạn đầu của kỷ nguyên khám phá không gian được thúc đẩy bởi \"Cuộc chạy đua vào không gian\" giữa Liên bang Xô viết và Hoa Kỳ. Việc Liên Xô phóng vệ tinh Sputnik 1 vào năm 1957 và chuyến đổ bộ lên Mặt Trăng đầu tiên của sứ mệnh Apollo 11 của Mỹ vào năm 1969 là những cột mốc quan trọng.\n",
    "\n",
    "Chương trình Apollo là chương trình bay vào không gian có người lái của Hoa Kỳ do NASA thực hiện, đã thành công trong việc đưa những con người đầu tiên đổ bộ lên Mặt Trăng. Apollo 11 là sứ mệnh đầu tiên hạ cánh xuống Mặt Trăng, được chỉ huy bởi Neil Armstrong và phi công mô-đun Mặt Trăng Buzz Aldrin, cùng với Michael Collins là phi công mô-đun điều khiển. Bước chân đầu tiên của Armstrong lên bề mặt Mặt Trăng diễn ra vào ngày 20 tháng 7 năm 1969 và được truyền hình trực tiếp trên toàn thế giới. Việc hạ cánh đã yêu cầu Armstrong phải điều khiển thủ công Mô-đun Mặt Trăng Eagle do các thách thức về định vị và tình trạng nhiên liệu thấp.\n",
    "\n",
    "Juno là một tàu thăm dò không gian của NASA đang bay quanh quỹ đạo Sao Mộc. Nó được phóng vào ngày 5 tháng 8 năm 2011 và tiến vào quỹ đạo cực của Sao Mộc vào ngày 5 tháng 7 năm 2016. Sứ mệnh của Juno là đo đạc thành phần, trọng trường, từ trường và từ quyển vùng cực của Sao Mộc để hiểu rõ cách hành tinh này hình thành. Juno là phi thuyền thứ hai bay quanh quỹ đạo Sao Mộc, sau tàu thăm dò Galileo. Nó được cung cấp năng lượng độc đáo bởi các tấm pin năng lượng Mặt Trời lớn thay vì máy phát nhiệt điện đồng vị phóng xạ (RTGs), giúp nó trở thành sứ mệnh sử dụng năng lượng Mặt Trời xa nhất.\n",
    "\n",
    "Xe tự hành Sao Hỏa (Mars rover) là một phương tiện cơ giới điều khiển từ xa được thiết kế để di chuyển trên bề mặt Sao Hỏa. NASA JPL đã quản lý thành công một số xe tự hành bao gồm: Sojourner, Spirit, Opportunity, Curiosity và Perseverance. Việc tìm kiếm bằng chứng về khả năng duy trì sự sống và carbon hữu cơ trên Sao Hỏa hiện là mục tiêu hàng đầu của NASA. Perseverance cũng mang theo trực thăng Ingenuity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4cb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5.Helper Functions for Chunking and Embedding\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Initialize tokenizer for robust, token-aware chunking\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def chunk_text(text, chunk_size=400, overlap=50):\n",
    "    \"\"\"Chunks text based on token count with overlap (Best practice for RAG).\"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk_tokens = tokens[i:i + chunk_size]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens)\n",
    "        # Basic cleanup\n",
    "        chunk_text = chunk_text.replace(\"\\n\", \" \").strip()\n",
    "        if chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "    return chunks\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_embeddings_batch(texts, model=EMBEDDING_MODEL):\n",
    "    \"\"\"Generates embeddings for a batch of texts using OpenAI, with retries.\"\"\"\n",
    "    # OpenAI expects the input texts to have newlines replaced by spaces\n",
    "    texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "    response = client.embeddings.create(input=texts, model=model)\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de9c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing and uploading Context Library to namespace: ContextLibrary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded 3 context vectors.\n",
      "\n",
      "Processing and uploading Knowledge Base to namespace: KnowledgeStore\n",
      "Created 3 knowledge chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded 3 knowledge vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@title 6.Process and Upload Data\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# --- 6.1. Context Library ---\n",
    "print(f\"\\nProcessing and uploading Context Library to namespace: {NAMESPACE_CONTEXT}\")\n",
    "\n",
    "vectors_context = []\n",
    "for item in tqdm(context_blueprints):\n",
    "    # We embed the DESCRIPTION (the intent)\n",
    "    embedding = get_embeddings_batch([item['description']])[0]\n",
    "    vectors_context.append({\n",
    "        \"id\": item['id'],\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {\n",
    "            \"description\": item['description'],\n",
    "            # The blueprint itself (JSON string) is stored as metadata\n",
    "            \"blueprint_json\": item['blueprint']\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Upsert data\n",
    "if vectors_context:\n",
    "    index.upsert(vectors=vectors_context, namespace=NAMESPACE_CONTEXT)\n",
    "    print(f\"Successfully uploaded {len(vectors_context)} context vectors.\")\n",
    "\n",
    "# --- 6.2. Knowledge Base ---\n",
    "print(f\"\\nProcessing and uploading Knowledge Base to namespace: {NAMESPACE_KNOWLEDGE}\")\n",
    "\n",
    "# Chunk the knowledge data\n",
    "knowledge_chunks = chunk_text(knowledge_data_raw)\n",
    "print(f\"Created {len(knowledge_chunks)} knowledge chunks.\")\n",
    "\n",
    "vectors_knowledge = []\n",
    "batch_size = 100 # Process in batches\n",
    "\n",
    "for i in tqdm(range(0, len(knowledge_chunks), batch_size)):\n",
    "    batch_texts = knowledge_chunks[i:i+batch_size]\n",
    "    batch_embeddings = get_embeddings_batch(batch_texts)\n",
    "\n",
    "    batch_vectors = []\n",
    "    for j, embedding in enumerate(batch_embeddings):\n",
    "        chunk_id = f\"knowledge_chunk_{i+j}\"\n",
    "        batch_vectors.append({\n",
    "            \"id\": chunk_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\n",
    "                \"text\": batch_texts[j]\n",
    "            }\n",
    "        })\n",
    "    # Upsert the batch\n",
    "    index.upsert(vectors=batch_vectors, namespace=NAMESPACE_KNOWLEDGE)\n",
    "\n",
    "print(f\"Successfully uploaded {len(knowledge_chunks)} knowledge vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60199dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingestion complete. Final Pinecone Index Stats (may take a moment to update):\n",
      "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
      "                                    'content-length': '220',\n",
      "                                    'content-type': 'application/json',\n",
      "                                    'date': 'Mon, 29 Dec 2025 01:59:52 GMT',\n",
      "                                    'grpc-status': '0',\n",
      "                                    'server': 'envoy',\n",
      "                                    'x-envoy-upstream-service-time': '3',\n",
      "                                    'x-pinecone-request-id': '637374064766665440',\n",
      "                                    'x-pinecone-request-latency-ms': '3',\n",
      "                                    'x-pinecone-response-duration-ms': '4'}},\n",
      " 'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'memoryFullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'ContextLibrary': {'vector_count': 3},\n",
      "                'KnowledgeStore': {'vector_count': 3}},\n",
      " 'storageFullness': 0.0,\n",
      " 'total_vector_count': 6,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "#@title 7.Final Verification\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"\\nIngestion complete. Final Pinecone Index Stats (may take a moment to update):\")\n",
    "time.sleep(15) # Give Pinecone a moment to update stats\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e109a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
